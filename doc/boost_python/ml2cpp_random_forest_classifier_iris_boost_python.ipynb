{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML2CPP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def populate_table(tablename, feature_names):\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data  \n",
    "    N = X.shape[0]\n",
    "    y = iris.target.reshape(N,1)\n",
    "    k = np.arange(N).reshape(N, 1)\n",
    "    k_X_y = np.concatenate((k, X, y) , axis=1)\n",
    "    lTable=pd.DataFrame(k_X_y)\n",
    "    # print(lTable.head())\n",
    "    lTable.columns = ['idx'] + feature_names + ['TGT'];\n",
    "    lTable['TGT'] = lTable['TGT'].apply(int)\n",
    "    lTable['idx'] = lTable['idx'].apply(int)\n",
    "    lTable.to_csv(tablename , float_format='%.14g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata = {\"primary_key\" : \"KEY\",\n",
    "            \"features\" : ['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm'],\n",
    "            \"targets\" : [\"TGT\"],\n",
    "            \"table\" : \"iris\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "populate_table(\"/tmp/iris.csv\" , metadata[\"features\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>sepal_length_cm</th>\n",
       "      <th>sepal_width_cm</th>\n",
       "      <th>petal_length_cm</th>\n",
       "      <th>petal_width_cm</th>\n",
       "      <th>TGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  idx  sepal_length_cm  sepal_width_cm  petal_length_cm  \\\n",
       "114         114  114              5.8             2.8              5.1   \n",
       "74           74   74              6.4             2.9              4.3   \n",
       "9             9    9              4.9             3.1              1.5   \n",
       "88           88   88              5.6             3.0              4.1   \n",
       "25           25   25              5.0             3.0              1.6   \n",
       "5             5    5              5.4             3.9              1.7   \n",
       "48           48   48              5.3             3.7              1.5   \n",
       "117         117  117              7.7             3.8              6.7   \n",
       "83           83   83              6.0             2.7              5.1   \n",
       "105         105  105              7.6             3.0              6.6   \n",
       "27           27   27              5.2             3.5              1.5   \n",
       "64           64   64              5.6             2.9              3.6   \n",
       "\n",
       "     petal_width_cm  TGT  \n",
       "114             2.4    2  \n",
       "74              1.3    1  \n",
       "9               0.1    0  \n",
       "88              1.3    1  \n",
       "25              0.2    0  \n",
       "5               0.4    0  \n",
       "48              0.2    0  \n",
       "117             2.2    2  \n",
       "83              1.6    1  \n",
       "105             2.1    2  \n",
       "27              0.2    0  \n",
       "64              1.3    1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/tmp/iris.csv\")\n",
    "df.sample(12, random_state=1960)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59460/2003923887.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(df[metadata['features']].values, df[metadata['targets']].values)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=512, random_state=1960)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=512, random_state=1960)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=512, random_state=1960)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# train any scikit model on the iris dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 512, random_state=1960)\n",
    "clf.fit(df[metadata['features']].values, df[metadata['targets']].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_cpp_for_model(model):\n",
    "    import pickle, json, requests, base64\n",
    "    b64_data = base64.b64encode(pickle.dumps(model)).decode('utf-8')\n",
    "    # send the model th the web service\n",
    "    json_data={\"Name\":\"model_cpp_sample\", \n",
    "               \"PickleData\":b64_data , \n",
    "               \"SQLDialect\":\"CPP\",\n",
    "               \"FeatureNames\" : metadata['features']}\n",
    "    r = requests.post(\"http://127.88.88.88:1888/model\", json=json_data)\n",
    "    content = r.json()\n",
    "    lCPP = content[\"model\"][\"SQLGenrationResult\"][0][\"SQL\"]\n",
    "    # print(lCPP);\n",
    "    return lCPP\n",
    "\n",
    "\n",
    "lCPPCode = generate_cpp_for_model(clf);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace  {\n",
      "\n",
      "\tstd::vector<std::any> get_classes(){\n",
      "\t\tstd::vector<std::any> lClasses = { 0, 1, 2 };\n",
      "\n",
      "\t\treturn lClasses;\n",
      "\t}\n",
      "\n",
      "\tnamespace RF_Tree_0 {\n",
      "\t\n",
      "\t\tstd::vector<std::any> get_classes(){\n",
      "\t\t\tstd::vector<std::any> lClasses = { 0, 1, 2 };\n",
      "\t\n",
      "\t\t\treturn lClasses;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttypedef std::vector<double> tNodeData;\n",
      "\t\tstd::map<int, tNodeData> Decision_Tree_Node_data = {\n",
      "\t\t\t\t{ 2 ,  {1.0, 0.0, 0.0 }} ,\n",
      "\t\t\t\t{ 4 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 5 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 8 ,  {1.0, 0.0, 0.0 }} ,\n",
      "\t\t\t\t{ 9 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 13 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 15 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 16 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 17 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 18 ,  {0.0, 0.0, 1.0 }} \n",
      "\t\t};\n",
      "\t\t\n",
      "\t\n",
      "\t\tint get_decision_tree_node_index(std::any Feature_0, std::any Feature_1, std::any Feature_2, std::any Feature_3) {\n",
      "\t\t\tint lNodeIndex = (Feature_0 <= 5.450000047683716) ? ( (Feature_3 <= 0.7000000029802322) ? ( 2 ) : ( (Feature_3 <= 1.600000023841858) ? ( 4 ) : ( 5 ) ) ) : ( (Feature_2 <= 4.75) ? ( (Feature_3 <= 0.6500000059604645) ? ( 8 ) : ( 9 ) ) : ( (Feature_3 <= 1.699999988079071) ? ( (Feature_1 <= 3.049999952316284) ? ( (Feature_3 <= 1.550000011920929) ? ( 13 ) : ( (Feature_0 <= 6.599999904632568) ? ( 15 ) : ( 16 ) ) ) : ( 17 ) ) : ( 18 ) ) );\n",
      "\t\t\n",
      "\t\t\treturn lNodeIndex;\n",
      "\t\t}\n",
      "\t\t\n",
      "\t\n",
      "\t\tstd::vector<std::string> get_input_names(){\n",
      "\t\t\tstd::vector<std::string> lFeatures = { \"Feature_0\", \"Feature_1\", \"Feature_2\", \"Feature_3\" };\n",
      "\t\n",
      "\t\t\treturn lFeatures;\n",
      "\t\t}\n",
      "\t\n",
      "\t\tstd::vector<std::string> get_output_names(){\n",
      "\t\t\tstd::vector<std::string> lOutputs = { \n",
      "\t\t\t\t\"Score_0\", \"Score_1\", \"Score_2\",\n",
      "\t\t\t\t\"Proba_0\", \"Proba_1\", \"Proba_2\",\n",
      "\t\t\t\t\"LogProba_0\", \"LogProba_1\", \"LogProba_2\",\n",
      "\t\t\t\t\"Decision\", \"DecisionProba\" };\n",
      "\t\n",
      "\t\t\treturn lOutputs;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttTable compute_classification_scores(std::any Feature_0, std::any Feature_1, std::any Feature_2, std::any Feature_3) {\n",
      "\t\t\tauto lClasses = get_classes();\n",
      "\t\n",
      "\t\t\tint lNodeIndex = get_decision_tree_node_index(Feature_0, Feature_1, Feature_2, Feature_3);\n",
      "\t\n",
      "\t\t\tstd::vector<double> lNodeValue = Decision_Tree_Node_data[ lNodeIndex ];\n",
      "\t\n",
      "\t\n",
      "\t\t\ttTable lTable;\n",
      "\t\n",
      "\t\t\tlTable[\"Score\"] = { \n",
      "\t\t\t\tstd::any(),\n",
      "\t\t\t\tstd::any(),\n",
      "\t\t\t\tstd::any() \n",
      "\t\t\t} ;\n",
      "\t\t\tlTable[\"Proba\"] = { \n",
      "\t\t\t\tlNodeValue [ 0 ],\n",
      "\t\t\t\tlNodeValue [ 1 ],\n",
      "\t\t\t\tlNodeValue [ 2 ] \n",
      "\t\t\t} ;\n",
      "\t\t\tint lBestClass = get_arg_max( lTable[\"Proba\"] );\n",
      "\t\t\tauto lDecision = lClasses[lBestClass];\n",
      "\t\t\tlTable[\"Decision\"] = { lDecision } ;\n",
      "\t\t\tlTable[\"DecisionProba\"] = { lTable[\"Proba\"][lBestClass] };\n",
      "\t\n",
      "\t\t\trecompute_log_probas( lTable );\n",
      "\t\n",
      "\t\t\treturn lTable;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttTable compute_model_outputs_from_table( tTable const & iTable) {\n",
      "\t\t\ttTable lTable = compute_classification_scores(iTable.at(\"Feature_0\")[0], iTable.at(\"Feature_1\")[0], iTable.at(\"Feature_2\")[0], iTable.at(\"Feature_3\")[0]);\n",
      "\t\n",
      "\t\t\treturn lTable;\n",
      "\t\t}\n",
      "\t\n",
      "\t} // eof namespace RF_Tree_0\n",
      "\t\n",
      "\n",
      "\tnamespace RF_Tree_1 {\n",
      "\t\n",
      "\t\tstd::vector<std::any> get_classes(){\n",
      "\t\t\tstd::vector<std::any> lClasses = { 0, 1, 2 };\n",
      "\t\n",
      "\t\t\treturn lClasses;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttypedef std::vector<double> tNodeData;\n",
      "\t\tstd::map<int, tNodeData> Decision_Tree_Node_data = {\n",
      "\t\t\t\t{ 1 ,  {1.0, 0.0, 0.0 }} ,\n",
      "\t\t\t\t{ 3 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 6 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 8 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 11 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 12 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 13 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 15 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 17 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 18 ,  {0.0, 0.0, 1.0 }} \n",
      "\t\t};\n",
      "\t\t\n",
      "\t\n",
      "\t\tint get_decision_tree_node_index(std::any Feature_0, std::any Feature_1, std::any Feature_2, std::any Feature_3) {\n",
      "\t\t\tint lNodeIndex = (Feature_2 <= 2.449999988079071) ? ( 1 ) : ( (Feature_2 <= 4.75) ? ( 3 ) : ( (Feature_3 <= 1.75) ? ( (Feature_1 <= 2.350000023841858) ? ( 6 ) : ( (Feature_1 <= 2.850000023841858) ? ( 8 ) : ( (Feature_1 <= 3.049999952316284) ? ( (Feature_3 <= 1.6500000357627869) ? ( 11 ) : ( 12 ) ) : ( 13 ) ) ) ) : ( (Feature_1 <= 3.149999976158142) ? ( 15 ) : ( (Feature_2 <= 4.950000047683716) ? ( 17 ) : ( 18 ) ) ) ) );\n",
      "\t\t\n",
      "\t\t\treturn lNodeIndex;\n",
      "\t\t}\n",
      "\t\t\n",
      "\t\n",
      "\t\tstd::vector<std::string> get_input_names(){\n",
      "\t\t\tstd::vector<std::string> lFeatures = { \"Feature_0\", \"Feature_1\", \"Feature_2\", \"Feature_3\" };\n",
      "\t\n",
      "\t\t\treturn lFeatures;\n",
      "\t\t}\n",
      "\t\n",
      "\t\tstd::vector<std::string> get_output_names(){\n",
      "\t\t\tstd::vector<std::string> lOutputs = { \n",
      "\t\t\t\t\"Score_0\", \"Score_1\", \"Score_2\",\n",
      "\t\t\t\t\"Proba_0\", \"Proba_1\", \"Proba_2\",\n",
      "\t\t\t\t\"LogProba_0\", \"LogProba_1\", \"LogProba_2\",\n",
      "\t\t\t\t\"Decision\", \"DecisionProba\" };\n",
      "\t\n",
      "\t\t\treturn lOutputs;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttTable compute_classification_scores(std::any Feature_0, std::any Feature_1, std::any Feature_2, std::any Feature_3) {\n",
      "\t\t\tauto lClasses = get_classes();\n",
      "\t\n",
      "\t\t\tint lNodeIndex = get_decision_tree_node_index(Feature_0, Feature_1, Feature_2, Feature_3);\n",
      "\t\n",
      "\t\t\tstd::vector<double> lNodeValue = Decision_Tree_Node_data[ lNodeIndex ];\n",
      "\t\n",
      "\t\n",
      "\t\t\ttTable lTable;\n",
      "\t\n",
      "\t\t\tlTable[\"Score\"] = { \n",
      "\t\t\t\tstd::any(),\n",
      "\t\t\t\tstd::any(),\n",
      "\t\t\t\tstd::any() \n",
      "\t\t\t} ;\n",
      "\t\t\tlTable[\"Proba\"] = { \n",
      "\t\t\t\tlNodeValue [ 0 ],\n",
      "\t\t\t\tlNodeValue [ 1 ],\n",
      "\t\t\t\tlNodeValue [ 2 ] \n",
      "\t\t\t} ;\n",
      "\t\t\tint lBestClass = get_arg_max( lTable[\"Proba\"] );\n",
      "\t\t\tauto lDecision = lClasses[lBestClass];\n",
      "\t\t\tlTable[\"Decision\"] = { lDecision } ;\n",
      "\t\t\tlTable[\"DecisionProba\"] = { lTable[\"Proba\"][lBestClass] };\n",
      "\t\n",
      "\t\t\trecompute_log_probas( lTable );\n",
      "\t\n",
      "\t\t\treturn lTable;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttTable compute_model_outputs_from_table( tTable const & iTable) {\n",
      "\t\t\ttTable lTable = compute_classification_scores(iTable.at(\"Feature_0\")[0], iTable.at(\"Feature_1\")[0], iTable.at(\"Feature_2\")[0], iTable.at(\"Feature_3\")[0]);\n",
      "\t\n",
      "\t\t\treturn lTable;\n",
      "\t\t}\n",
      "\t\n",
      "\t} // eof namespace RF_Tree_1\n",
      "\t\n",
      "\n",
      "\tnamespace RF_Tree_2 {\n",
      "\t\n",
      "\t\tstd::vector<std::any> get_classes(){\n",
      "\t\t\tstd::vector<std::any> lClasses = { 0, 1, 2 };\n",
      "\t\n",
      "\t\t\treturn lClasses;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttypedef std::vector<double> tNodeData;\n",
      "\t\tstd::map<int, tNodeData> Decision_Tree_Node_data = {\n",
      "\t\t\t\t{ 1 ,  {1.0, 0.0, 0.0 }} ,\n",
      "\t\t\t\t{ 5 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 7 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 8 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 9 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 12 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 14 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 15 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 16 ,  {0.0, 0.0, 1.0 }} \n",
      "\t\t};\n",
      "\t\t\n",
      "\t\n",
      "\t\tint get_decision_tree_node_index(std::any Feature_0, std::any Feature_1, std::any Feature_2, std::any Feature_3) {\n",
      "\t\t\tint lNodeIndex = (Feature_3 <= 0.75) ? ( 1 ) : ( (Feature_3 <= 1.6500000357627869) ? ( (Feature_1 <= 2.649999976158142) ? ( (Feature_0 <= 5.900000095367432) ? ( 5 ) : ( (Feature_2 <= 4.950000047683716) ? ( 7 ) : ( 8 ) ) ) : ( 9 ) ) : ( (Feature_2 <= 4.8500001430511475) ? ( (Feature_0 <= 5.400000095367432) ? ( 12 ) : ( (Feature_1 <= 3.100000023841858) ? ( 14 ) : ( 15 ) ) ) : ( 16 ) ) );\n",
      "\t\t\n",
      "\t\t\treturn lNodeIndex;\n",
      "\t\t}\n",
      "\t\t\n",
      "\t\n",
      "\t\tstd::vector<std::string> get_input_names(){\n",
      "\t\t\tstd::vector<std::string> lFeatures = { \"Feature_0\", \"Feature_1\", \"Feature_2\", \"Feature_3\" };\n",
      "\t\n",
      "\t\t\treturn lFeatures;\n",
      "\t\t}\n",
      "\t\n",
      "\t\tstd::vector<std::string> get_output_names(){\n",
      "\t\t\tstd::vector<std::string> lOutputs = { \n",
      "\t\t\t\t\"Score_0\", \"Score_1\", \"Score_2\",\n",
      "\t\t\t\t\"Proba_0\", \"Proba_1\", \"Proba_2\",\n",
      "\t\t\t\t\"LogProba_0\", \"LogProba_1\", \"LogProba_2\",\n",
      "\t\t\t\t\"Decision\", \"DecisionProba\" };\n",
      "\t\n",
      "\t\t\treturn lOutputs;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttTable compute_classification_scores(std::any Feature_0, std::any Feature_1, std::any Feature_2, std::any Feature_3) {\n",
      "\t\t\tauto lClasses = get_classes();\n",
      "\t\n",
      "\t\t\tint lNodeIndex = get_decision_tree_node_index(Feature_0, Feature_1, Feature_2, Feature_3);\n",
      "\t\n",
      "\t\t\tstd::vector<double> lNodeValue = Decision_Tree_Node_data[ lNodeIndex ];\n",
      "\t\n",
      "\t\n",
      "\t\t\ttTable lTable;\n",
      "\t\n",
      "\t\t\tlTable[\"Score\"] = { \n",
      "\t\t\t\tstd::any(),\n",
      "\t\t\t\tstd::any(),\n",
      "\t\t\t\tstd::any() \n",
      "\t\t\t} ;\n",
      "\t\t\tlTable[\"Proba\"] = { \n",
      "\t\t\t\tlNodeValue [ 0 ],\n",
      "\t\t\t\tlNodeValue [ 1 ],\n",
      "\t\t\t\tlNodeValue [ 2 ] \n",
      "\t\t\t} ;\n",
      "\t\t\tint lBestClass = get_arg_max( lTable[\"Proba\"] );\n",
      "\t\t\tauto lDecision = lClasses[lBestClass];\n",
      "\t\t\tlTable[\"Decision\"] = { lDecision } ;\n",
      "\t\t\tlTable[\"DecisionProba\"] = { lTable[\"Proba\"][lBestClass] };\n",
      "\t\n",
      "\t\t\trecompute_log_probas( lTable );\n",
      "\t\n",
      "\t\t\treturn lTable;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttTable compute_model_outputs_from_table( tTable const & iTable) {\n",
      "\t\t\ttTable lTable = compute_classification_scores(iTable.at(\"Feature_0\")[0], iTable.at(\"Feature_1\")[0], iTable.at(\"Feature_2\")[0], iTable.at(\"Feature_3\")[0]);\n",
      "\t\n",
      "\t\t\treturn lTable;\n",
      "\t\t}\n",
      "\t\n",
      "\t} // eof namespace RF_Tree_2\n",
      "\t\n",
      "\n",
      "\tnamespace RF_Tree_3 {\n",
      "\t\n",
      "\t\tstd::vector<std::any> get_classes(){\n",
      "\t\t\tstd::vector<std::any> lClasses = { 0, 1, 2 };\n",
      "\t\n",
      "\t\t\treturn lClasses;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttypedef std::vector<double> tNodeData;\n",
      "\t\tstd::map<int, tNodeData> Decision_Tree_Node_data = {\n",
      "\t\t\t\t{ 1 ,  {1.0, 0.0, 0.0 }} ,\n",
      "\t\t\t\t{ 4 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 5 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 8 ,  {0.0, 1.0, 0.0 }} ,\n",
      "\t\t\t\t{ 9 ,  {0.0, 0.0, 1.0 }} ,\n",
      "\t\t\t\t{ 10 ,  {0.0, 0.0, 1.0 }} \n",
      "\t\t};\n",
      "\t\t\n",
      "\t\n",
      "\t\tint get_decision_tree_node_index(std::any Feature_0, std::any Feature_1, std::any Feature_2, std::any Feature_3) {\n",
      "\t\t\tint lNodeIndex = (Feature_3 <= 0.800000011920929) ? ( 1 ) : ( (Feature_2 <= 4.75) ? ( (Feature_3 <= 1.6500000357627869) ? ( 4 ) : ( 5 ) ) : ( (Feature_2 <= 4.950000047683716) ? ( (Feature_1 <= 2.600000023841858) ? ( 8 ) : ( 9 ) ) : ( 10 ) ) );\n",
      "\t\t\n",
      "\t\t\treturn lNodeIndex;\n",
      "\t\t}\n",
      "\t\t\n",
      "\t\n",
      "\t\tstd::vector<std::string> get_input_names(){\n",
      "\t\t\tstd::vector<std::string> lFeatures = { \"Feature_0\", \"Feature_1\", \"Feature_2\", \"Feature_3\" };\n",
      "\t\n",
      "\t\t\treturn lFeatures;\n",
      "\t\t}\n",
      "\t\n",
      "\t\tstd::vector<std::string> get_output_names(){\n",
      "\t\t\tstd::vector<std::string> lOutputs = { \n",
      "\t\t\t\t\"Score_0\", \"Score_1\", \"Score_2\",\n",
      "\t\t\t\t\"Proba_0\", \"Proba_1\", \"Proba_2\",\n",
      "\t\t\t\t\"LogProba_0\", \"LogProba_1\", \"LogProba_2\",\n",
      "\t\t\t\t\"Decision\", \"DecisionProba\" };\n",
      "\t\n",
      "\t\t\treturn lOutputs;\n",
      "\t\t}\n",
      "\t\n",
      "\t\ttTable compute_classification_scores(std::any Feature_0, std::any Feature_1, std::any Feature_2, std::any Feature_3) {\n",
      "\t\t\tauto lClasses = get_classes();\n",
      "\t\n",
      "\t\t\tint lNodeIndex = get_decision_tree_node_index(Feature_0, Feature_1, Feature_2, Feature_3);\n",
      "\t\n",
      "\t\t\tstd::vector<double> lNodeValue = Decision_Tree_Node_data[ lNodeIndex ];\n",
      "\t\n",
      "\t\n",
      "\t\t\ttTable lTable;\n",
      "\t\n",
      "\t\t\tlTable[\"Score\"] = { \n",
      "\t\t\t\tstd::any(),\n",
      "\t\t\t\tstd::any(),\n",
      "\t\t\t\tstd::any() \n",
      "\t\t\t} ;\n",
      "\t\t\tlTable[\"Proba\"] = { \n",
      "\t\t\t\tlNodeValue [ 0 ],\n",
      "\t\t\t\tlNodeValue [ 1 ],\n",
      "\t\t\t\tlNodeValue [ 2 ] \n",
      "\t\t\t} ;\n",
      "\t\t\tint lBestClass = get_arg_max( lTable[\"Proba\"] );\n",
      "\t\t\tauto lDecision = lClasses[lBestClass];\n",
      "\t\t\tlTable[\"Decision\"] = { lDecision } ;\n",
      "\t\t\tlTable[\"DecisionProba\"] = { \n",
      "\n",
      "\n",
      " .... \n",
      "\n",
      "\n",
      "::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_410::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_411::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_412::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_413::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_414::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_415::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_416::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_417::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_418::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_419::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_420::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_421::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_422::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_423::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_424::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_425::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_426::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_427::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_428::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_429::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_430::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_431::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_432::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_433::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_434::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_435::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_436::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_437::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_438::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_439::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_440::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_441::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_442::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_443::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_444::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_445::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_446::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_447::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_448::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_449::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_450::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_451::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_452::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_453::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_454::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_455::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_456::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_457::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_458::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_459::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_460::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_461::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_462::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_463::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_464::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_465::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_466::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_467::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_468::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_469::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_470::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_471::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_472::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_473::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_474::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_475::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_476::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_477::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_478::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_479::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_480::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_481::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_482::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_483::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_484::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_485::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_486::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_487::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_488::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_489::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_490::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_491::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_492::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_493::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_494::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_495::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_496::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_497::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_498::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_499::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_500::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_501::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_502::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_503::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_504::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_505::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_506::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_507::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_508::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_509::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_510::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3),\n",
      "\t\t\tRF_Tree_511::compute_classification_scores(Feature_0, Feature_1, Feature_2, Feature_3)\n",
      "\t\t};\n",
      "\n",
      "\t\ttTable lAggregatedTable = aggregate_rf_scores(lTreeScores, {\"Proba\", \"Score\"});\n",
      "\n",
      "\n",
      "\t\ttTable lTable = lAggregatedTable;\n",
      "\n",
      "\t\tint lBestClass = get_arg_max( lTable[\"Proba\"] );\n",
      "\t\tauto lDecision = lClasses[lBestClass];\n",
      "\t\tlTable[\"Decision\"] = { lDecision } ;\n",
      "\t\tlTable[\"DecisionProba\"] = { lTable[\"Proba\"][lBestClass] };\n",
      "\n",
      "\t\trecompute_log_probas( lTable );\n",
      "\n",
      "\t\treturn lTable;\n",
      "\t}\n",
      "\n",
      "\ttTable compute_model_outputs_from_table( tTable const & iTable) {\n",
      "\t\ttTable lTable = compute_classification_scores(iTable.at(\"Feature_0\")[0], iTable.at(\"Feature_1\")[0], iTable.at(\"Feature_2\")[0], iTable.at(\"Feature_3\")[0]);\n",
      "\n",
      "\t\treturn lTable;\n",
      "\t}\n",
      "\n",
      "} // eof namespace \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lCPPCode[:10000] + \"\\n\\n\\n .... \\n\\n\\n\" + lCPPCode[-10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    def write_text_to_file(iCPPCode, oCPPFile):          \n",
    "        with open(oCPPFile, \"w\") as text_file:\n",
    "            text_file.write(iCPPCode)\n",
    "\n",
    "    def add_cpp_boost_layer(iModelName):\n",
    "        lCPPCode = \"#include \\\"Generic.i\\\"\\n\"\n",
    "        lCPPCode = lCPPCode + \"#include \\\"/tmp/\" + iModelName + \"_model_specific.i\\\"\\n\\n\"\n",
    "        lCPPCode = lCPPCode + \"#include <boost/python.hpp>\\n\"\n",
    "        lCPPCode = lCPPCode + \"using namespace boost::python;\\n\\n\"\n",
    "        lCPPCode = lCPPCode + \"BOOST_PYTHON_MODULE(\" + iModelName + \") {\\n\"\n",
    "        lCPPCode = lCPPCode + \"\\tdef(\\\"score_csv_file\\\", score_csv_file); \\n\"\n",
    "        lCPPCode = lCPPCode + \"}\\n\"\n",
    "        lCPPCode = lCPPCode + \"\\n\"\n",
    "        return lCPPCode \n",
    "         \n",
    "\n",
    "    def compile_cpp_code_as_shared_lib(iName):\n",
    "        import subprocess\n",
    "        # g++ -I$(PYTHON_INCLUDE) -I$(BOOST_INC) -fPIC -c $(TARGET).C\n",
    "        lCommand = [\"g++\", \"-I/usr/include/python3.10\", \"-Wno-unused-function\", \n",
    "                    \"-fPIC\", \"-std=c++17\" , \"-g\" ,  \n",
    "                    \"-o\",  iName + \".o\",\n",
    "                    \"-c\",  iName + \".cpp\"]\n",
    "        print(\"EXECUTING\" , \"'\" + \" \".join(lCommand) + \"'\")\n",
    "        result = subprocess.check_output(lCommand)\n",
    "        # \tg++ -shared -Wl,--export-dynamic $(TARGET).o -L$(BOOST_LIB) -lboost_python-$(PYTHON_VERSION) -L/usr/lib/python$(PYTHON_VERSION)/config -lpython$(PYTHON_VERSION) -o $(TARGET).so\n",
    "        lCommand2 = [\"g++\" , iName + \".o\", \"-shared\",  \"-Wl,--export-dynamic\",  \"-lboost_python310\", \"-L/usr/lib/python3.10/config\" , \"-lpython3.10\" ,  \"-o\",  iName + \".so\" ]\n",
    "        print(\"EXECUTING\" , \"'\" + \" \".join(lCommand2) + \"'\")\n",
    "        result2 = subprocess.check_output(lCommand2)\n",
    "        # print(result)\n",
    "\n",
    "    def execute_boost_python_model(iModelName, iCSVFile):\n",
    "        import sys\n",
    "        sys.path = sys.path + ['/tmp']\n",
    "        import importlib\n",
    "        lModelPythonModule = importlib.import_module(iModelName)\n",
    "        result2 = lModelPythonModule.score_csv_file(iCSVFile)\n",
    "        print(result2[:10])\n",
    "        print(result2[-10:])\n",
    "        return result2\n",
    "        \n",
    "    def deploy_cpp_code_in_python(iCPPCode, iCSVFile):\n",
    "        lModelName = \"sklearn2sql_cpp_\" + str(id(clf))\n",
    "        lName = \"/tmp/\" + lModelName;\n",
    "        write_text_to_file(iCPPCode, lName + \"_model_specific.i\")\n",
    "        lCPPCode = add_cpp_boost_layer(lModelName)\n",
    "        print(\"BOOST_PYTHON_LAYER_START\")\n",
    "        print(lCPPCode)\n",
    "        print(\"BOOST_PYTHON_LAYER_END\")\n",
    "        write_text_to_file(lCPPCode, lName + \".cpp\")\n",
    "        compile_cpp_code_as_shared_lib(lName)\n",
    "        result = execute_boost_python_model(lModelName, iCSVFile)\n",
    "        write_text_to_file(str(result), lName + \".out\")\n",
    "        return lName + \".out\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOST_PYTHON_LAYER_START\n",
      "#include \"Generic.i\"\n",
      "#include \"/tmp/sklearn2sql_cpp_140201627744480_model_specific.i\"\n",
      "\n",
      "#include <boost/python.hpp>\n",
      "using namespace boost::python;\n",
      "\n",
      "BOOST_PYTHON_MODULE(sklearn2sql_cpp_140201627744480) {\n",
      "\tdef(\"score_csv_file\", score_csv_file); \n",
      "}\n",
      "\n",
      "\n",
      "BOOST_PYTHON_LAYER_END\n",
      "EXECUTING 'g++ -I/usr/include/python3.10 -Wno-unused-function -fPIC -std=c++17 -g -o /tmp/sklearn2sql_cpp_140201627744480.o -c /tmp/sklearn2sql_cpp_140201627744480.cpp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from /usr/include/boost/smart_ptr/detail/sp_thread_sleep.hpp:22,\n",
      "                 from /usr/include/boost/smart_ptr/detail/yield_k.hpp:23,\n",
      "                 from /usr/include/boost/smart_ptr/detail/spinlock_gcc_atomic.hpp:14,\n",
      "                 from /usr/include/boost/smart_ptr/detail/spinlock.hpp:42,\n",
      "                 from /usr/include/boost/smart_ptr/detail/spinlock_pool.hpp:25,\n",
      "                 from /usr/include/boost/smart_ptr/shared_ptr.hpp:29,\n",
      "                 from /usr/include/boost/shared_ptr.hpp:17,\n",
      "                 from /usr/include/boost/python/converter/shared_ptr_to_python.hpp:12,\n",
      "                 from /usr/include/boost/python/converter/arg_to_python.hpp:15,\n",
      "                 from /usr/include/boost/python/call.hpp:15,\n",
      "                 from /usr/include/boost/python/object_core.hpp:14,\n",
      "                 from /usr/include/boost/python/args.hpp:22,\n",
      "                 from /usr/include/boost/python.hpp:11,\n",
      "                 from /tmp/sklearn2sql_cpp_140201627744480.cpp:4:\n",
      "/usr/include/boost/bind.hpp:36:1: note: ‘#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.’\n",
      "   36 | BOOST_PRAGMA_MESSAGE(\n",
      "      | ^~~~~~~~~~~~~~~~~~~~\n",
      "/usr/include/boost/detail/iterator.hpp:13:1: note: ‘#pragma message: This header is deprecated. Use <iterator> instead.’\n",
      "   13 | BOOST_HEADER_DEPRECATED(\"<iterator>\")\n",
      "      | ^~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTING 'g++ /tmp/sklearn2sql_cpp_140201627744480.o -shared -Wl,--export-dynamic -lboost_python310 -L/usr/lib/python3.10/config -lpython3.10 -o /tmp/sklearn2sql_cpp_140201627744480.so'\n",
      "idx,Score_0,Score_1,Score_2,Proba_0,Proba_1,Proba_2,LogProba_0,LogProba_1,LogProba_2,Decision,DecisionProba\n",
      "0,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "1,,,,0.99804687500000,0.00195312500000,0.00000000000000,-0.00195503483580,-6.23832462503951,-32.23619130191664,0,0.99804687500000\n",
      "2,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "3,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "4,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "5,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "6,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "7,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "8,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "9,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "10,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "11,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "12,,,,0.99804687500000,0.00195312500000,0.00000000000000,-0.00195503483580,-6.23832462503951,-32.23619130191664,0,0.99804687500000\n",
      "13,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "14,,,,0.98632812500000,0.01367187500000,0.00000000000000,-0.01376619576415,-4.29241447598419,-32.23619130191664,0,0.98632812500000\n",
      "15,,,,0.99023437500000,0.00976562500000,0.00000000000000,-0.00981362144833,-4.62888671260541,-32.23619130191664,0,0.99023437500000\n",
      "16,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "17,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "18,,,,0.98828125000000,0.01171875000000,0.00000000000000,-0.01178795575204,-4.44656515581145,-32.23619130191664,0,0.98828125000000\n",
      "19,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "20,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "21,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "22,,,,1.000000000000idx,Score_\n",
      "000000000\n",
      "\n",
      "00,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "23,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "24,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "25,,,,0.99609375000000,0.00390625000000,0.00000000000000,-0.00391389932114,-5.54517744447956,-32.23619130191664,0,0.99609375000000\n",
      "26,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "27,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "28,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "29,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "30,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "31,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "32,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "33,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "34,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "35,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "36,,,,0.97851562500000,0.02148437500000,0.00000000000000,-0.02171852395464,-3.84042935224114,-32.23619130191664,0,0.97851562500000\n",
      "37,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "38,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "39,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "40,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "41,,,,0.98828125000000,0.01171875000000,0.00000000000000,-0.01178795575204,-4.44656515581145,-32.23619130191664,0,0.98828125000000\n",
      "42,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "43,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "44,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "45,,,,0.99804687500000,0.00195312500000,0.00000000000000,-0.00195503483580,-6.23832462503951,-32.23619130191664,0,0.99804687500000\n",
      "46,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "47,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "48,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "49,,,,1.00000000000000,0.00000000000000,0.00000000000000,0.00000000000000,-32.23619130191664,-32.23619130191664,0,1.00000000000000\n",
      "50,,,,0.00000000000000,0.99804687500000,0.00195312500000,-32.23619130191664,-0.00195503483580,-6.23832462503951,1,0.99804687500000\n",
      "51,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "52,,,,0.00000000000000,0.90820312500000,0.09179687500000,-32.23619130191664,-0.09628721945215,-2.38817702332945,1,0.90820312500000\n",
      "53,,,,0.00000000000000,0.99609375000000,0.00390625000000,-32.23619130191664,-0.00391389932114,-5.54517744447956,1,0.99609375000000\n",
      "54,,,,0.00000000000000,0.98828125000000,0.01171875000000,-32.23619130191664,-0.01178795575204,-4.44656515581145,1,0.98828125000000\n",
      "55,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "56,,,,0.00195312500000,0.96484375000000,0.03320312500000,-6.23832462503951,-0.03578910785159,-3.40511128098329,1,0.96484375000000\n",
      "57,,,,0.00390625000000,0.90429687500000,0.09179687500000,-5.54517744447956,-0.10059757095327,-2.38817702332945,1,0.90429687500000\n",
      "58,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "59,,,,0.00195312500000,0.98632812500000,0.01171875000000,-6.23832462503951,-0.01376619576415,-4.44656515581145,1,0.98632812500000\n",
      "60,,,,0.00000000000000,0.97460937500000,0.02539062500000,-32.23619130191664,-0.02571852928799,-3.67337526757797,1,0.97460937500000\n",
      "61,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "62,,,,0.00000000000000,0.96093750000000,0.03906250000000,-32.23619130191664,-0.03984590854720,-3.24259235148552,1,0.96093750000000\n",
      "63,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "64,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "65,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "66,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "67,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "68,,,,0.00000000000000,0.95507812500000,0.04492187500000,-32.23619130191664,-0.04596213556464,-3.10283040911036,1,0.95507812500000\n",
      "69,,,,0.00000000000000,0.99804687500000,0.00195312500000,-32.23619130191664,-0.00195503483580,-6.23832462503951,1,0.99804687500000\n",
      "70,,,,0.00000000000000,0.64843750000000,0.35156250000000,-32.23619130191664,-0.43318965612302,-1.04536777414930,1,0.64843750000000\n",
      "71,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "72,,,,0.00000000000000,0.83789062500000,0.16210937500000,-32.23619130191664,-0.17686770611149,-1.81948401724291,1,0.83789062500000\n",
      "73,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "74,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "75,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "76,,,,0.00000000000000,0.95117187500000,0.04882812500000,-32.23619130191664,-0.05006050195692,-3.01944880017131,1,0.95117187500000\n",
      "77,,,,0.00000000000000,0.65039062500000,0.34960937500000,-32.23619130191664,-0.43018213505906,-1.05093881919875,1,0.65039062500000\n",
      "78,,,,0.00000000000000,0.99804687500000,0.00195312500000,-32.23619130191664,-0.00195503483580,-6.23832462503951,1,0.99804687500000\n",
      "79,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "80,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "81,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "82,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "83,,,,0.00000000000000,0.69726562500000,0.30273437500000,-32.23619130191664,-0.36058884325987,-1.19489950812026,1,0.69726562500000\n",
      "84,,,,0.01953125000000,0.95898437500000,0.02148437500000,-3.93573953204546,-0.04188049724499,-3.84042935224114,1,0.95898437500000\n",
      "85,,,,0.00976562500000,0.96679687500000,0.02343750000000,-4.62888671260541,-0.03376686247082,-3.75341797525151,1,0.96679687500000\n",
      "86,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "87,,,,0.00000000000000,0.99023437500000,0.00976562500000,-32.23619130191664,-0.00981362144832,-4.62888671260541,1,0.99023437500000\n",
      "88,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "89,,,,0.00000000000000,0.99804687500000,0.00195312500000,-32.23619130191664,-0.00195503483580,-6.23832462503951,1,0.99804687500000\n",
      "90,,,,0.00000000000000,0.99609375000000,0.00390625000000,-32.23619130191664,-0.00391389932114,-5.54517744447956,1,0.99609375000000\n",
      "91,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "92,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "93,,,,0.00390625000000,0.98046875000000,0.01562500000000,-5.54517744447956,-0.01972450534778,-4.15888308335967,1,0.98046875000000\n",
      "94,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "95,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "96,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "97,,,,0.00000000000000,0.99609375000000,0.00390625000000,-32.23619130191664,-0.00391389932114,-5.54517744447956,1,0.99609375000000\n",
      "98,,,,0.00390625000000,0.98632812500000,0.00976562500000,-5.54517744447956,-0.01376619576415,-4.62888671260541,1,0.98632812500000\n",
      "99,,,,0.00000000000000,1.00000000000000,0.00000000000000,-32.23619130191664,0.00000000000000,-32.23619130191664,1,1.00000000000000\n",
      "100,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "101,,,,0.00000000000000,0.01562500000000,0.98437500000000,-32.23619130191664,-4.15888308335967,-0.01574835696814,2,0.98437500000000\n",
      "102,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "103,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "104,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "105,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "106,,,,0.00195312500000,0.34179687500000,0.65625000000000,-6.23832462503951,-1.07353865111599,-0.42121346507630,2,0.65625000000000\n",
      "107,,,,0.00000000000000,0.00195312500000,0.99804687500000,-32.23619130191664,-6.23832462503951,-0.00195503483580,2,0.99804687500000\n",
      "108,,,,0.00000000000000,0.01171875000000,0.98828125000000,-32.23619130191664,-4.44656515581145,-0.01178795575204,2,0.98828125000000\n",
      "109,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "110,,,,0.00000000000000,0.00585937500000,0.99414062500000,-32.23619130191664,-5.13971233637140,-0.00587660848899,2,0.99414062500000\n",
      "111,,,,0.00000000000000,0.00781250000000,0.99218750000000,-32.23619130191664,-4.85203026391962,-0.00784317746103,2,0.99218750000000\n",
      "112,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "113,,,,0.00000000000000,0.00976562500000,0.99023437500000,-32.23619130191664,-4.62888671260541,-0.00981362144833,2,0.99023437500000\n",
      "114,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "115,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "116,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "117,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "118,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "119,,,,0.00000000000000,0.27539062500000,0.72460937500000,-32.23619130191664,-1.28956473466134,-0.32212256243207,2,0.72460937500000\n",
      "120,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "121,,,,0.00000000000000,0.054687500000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COLUMN_GUESSED_AS_INT  150\n",
      "COLUMN_GUESSED_AS_INT idx 150\n",
      "COLUMN_GUESSED_AS_DOUBLE Feature_0 150\n",
      "COLUMN_GUESSED_AS_DOUBLE Feature_1 150\n",
      "COLUMN_GUESSED_AS_DOUBLE Feature_2 150\n",
      "COLUMN_GUESSED_AS_DOUBLE Feature_3 150\n",
      "COLUMN_GUESSED_AS_INT TGT 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00,0.94531250000000,-32.23619130191664,-2.90612011486430,-0.05623971832288,2,0.94531250000000\n",
      "122,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "123,,,,0.00000000000000,0.04492187500000,0.95507812500000,-32.23619130191664,-3.10283040911036,-0.04596213556464,2,0.95507812500000\n",
      "124,,,,0.00000000000000,0.00195312500000,0.99804687500000,-32.23619130191664,-6.23832462503951,-0.00195503483580,2,0.99804687500000\n",
      "125,,,,0.00000000000000,0.00781250000000,0.99218750000000,-32.23619130191664,-4.85203026391962,-0.00784317746103,2,0.99218750000000\n",
      "126,,,,0.00000000000000,0.09570312500000,0.90429687500000,-32.23619130191664,-2.34650432692888,-0.10059757095327,2,0.90429687500000\n",
      "127,,,,0.00000000000000,0.02734375000000,0.97265625000000,-32.23619130191664,-3.59926729542425,-0.02772454801486,2,0.97265625000000\n",
      "128,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "129,,,,0.00000000000000,0.17773437500000,0.82226562500000,-32.23619130191664,-1.72746511852266,-0.19569179135713,2,0.82226562500000\n",
      "130,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "131,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "132,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "133,,,,0.00000000000000,0.27539062500000,0.72460937500000,-32.23619130191664,-1.28956473466134,-0.32212256243207,2,0.72460937500000\n",
      "134,,,,0.00000000000000,0.15625000000000,0.84375000000000,-32.23619130191664,-1.85629799036563,-0.16989903679540,2,0.84375000000000\n",
      "135,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "136,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "137,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "138,,,,0.00000000000000,0.18164062500000,0.81835937500000,-32.23619130191664,-1.70572513188625,-0.20045370511737,2,0.81835937500000\n",
      "139,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "140,,,,0.00000000000000,0.00195312500000,0.99804687500000,-32.23619130191664,-6.23832462503951,-0.00195503483580,2,0.99804687500000\n",
      "141,,,,0.00000000000000,0.00976562500000,0.99023437500000,-32.23619130191664,-4.62888671260541,-0.00981362144832,2,0.99023437500000\n",
      "142,,,,0.00000000000000,0.01562500000000,0.98437500000000,-32.23619130191664,-4.15888308335967,-0.01574835696814,2,0.98437500000000\n",
      "143,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "144,,,,0.00000000000000,0.00195312500000,0.99804687500000,-32.23619130191664,-6.23832462503951,-0.00195503483580,2,0.99804687500000\n",
      "145,,,,0.00000000000000,0.00390625000000,0.99609375000000,-32.23619130191664,-5.54517744447956,-0.00391389932114,2,0.99609375000000\n",
      "146,,,,0.00000000000000,0.01953125000000,0.98046875000000,-32.23619130191664,-3.93573953204546,-0.01972450534778,2,0.98046875000000\n",
      "147,,,,0.00000000000000,0.00000000000000,1.00000000000000,-32.23619130191664,-32.23619130191664,0.00000000000000,2,1.00000000000000\n",
      "148,,,,0.00000000000000,0.00976562500000,0.99023437500000,-32.23619130191664,-4.62888671260541,-0.00981362144832,2,0.99023437500000\n",
      "149,,,,0.00000000000000,0.03125000000000,0.96875000000000,-32.23619130191664,-3.46573590279973,-0.03174869831458,2,0.96875000000000\n"
     ]
    }
   ],
   "source": [
    "populate_table(\"/tmp/iris2.csv\" , [\"Feature_0\", \"Feature_1\", \"Feature_2\", \"Feature_3\"])\n",
    "lCPPOutput = deploy_cpp_code_in_python(lCPPCode , \"/tmp/iris2.csv\")\n",
    "cpp_output = pd.read_csv(lCPPOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Score_0</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Proba_0</th>\n",
       "      <th>Proba_1</th>\n",
       "      <th>Proba_2</th>\n",
       "      <th>LogProba_0</th>\n",
       "      <th>LogProba_1</th>\n",
       "      <th>LogProba_2</th>\n",
       "      <th>Decision</th>\n",
       "      <th>DecisionProba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003914</td>\n",
       "      <td>-5.545177</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.697266</td>\n",
       "      <td>0.302734</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-0.360589</td>\n",
       "      <td>-1.194900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.697266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx  Score_0  Score_1  Score_2   Proba_0   Proba_1   Proba_2  LogProba_0  \\\n",
       "114  114      NaN      NaN      NaN  0.000000  0.000000  1.000000  -32.236191   \n",
       "74    74      NaN      NaN      NaN  0.000000  1.000000  0.000000  -32.236191   \n",
       "9      9      NaN      NaN      NaN  1.000000  0.000000  0.000000    0.000000   \n",
       "88    88      NaN      NaN      NaN  0.000000  1.000000  0.000000  -32.236191   \n",
       "25    25      NaN      NaN      NaN  0.996094  0.003906  0.000000   -0.003914   \n",
       "5      5      NaN      NaN      NaN  1.000000  0.000000  0.000000    0.000000   \n",
       "48    48      NaN      NaN      NaN  1.000000  0.000000  0.000000    0.000000   \n",
       "117  117      NaN      NaN      NaN  0.000000  0.000000  1.000000  -32.236191   \n",
       "83    83      NaN      NaN      NaN  0.000000  0.697266  0.302734  -32.236191   \n",
       "105  105      NaN      NaN      NaN  0.000000  0.000000  1.000000  -32.236191   \n",
       "27    27      NaN      NaN      NaN  1.000000  0.000000  0.000000    0.000000   \n",
       "64    64      NaN      NaN      NaN  0.000000  1.000000  0.000000  -32.236191   \n",
       "\n",
       "     LogProba_1  LogProba_2  Decision  DecisionProba  \n",
       "114  -32.236191    0.000000         2       1.000000  \n",
       "74     0.000000  -32.236191         1       1.000000  \n",
       "9    -32.236191  -32.236191         0       1.000000  \n",
       "88     0.000000  -32.236191         1       1.000000  \n",
       "25    -5.545177  -32.236191         0       0.996094  \n",
       "5    -32.236191  -32.236191         0       1.000000  \n",
       "48   -32.236191  -32.236191         0       1.000000  \n",
       "117  -32.236191    0.000000         2       1.000000  \n",
       "83    -0.360589   -1.194900         1       0.697266  \n",
       "105  -32.236191    0.000000         2       1.000000  \n",
       "27   -32.236191  -32.236191         0       1.000000  \n",
       "64     0.000000  -32.236191         1       1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_output.sample(12, random_state=1960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/ensemble/_forest.py:922: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Score_0</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Proba_0</th>\n",
       "      <th>Proba_1</th>\n",
       "      <th>Proba_2</th>\n",
       "      <th>LogProba_0</th>\n",
       "      <th>LogProba_1</th>\n",
       "      <th>LogProba_2</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003914</td>\n",
       "      <td>-5.545177</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699219</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-0.357792</td>\n",
       "      <td>-1.201372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx Score_0 Score_1 Score_2   Proba_0   Proba_1   Proba_2  LogProba_0  \\\n",
       "114  114     NaN     NaN     NaN  0.000000  0.000000  1.000000        -inf   \n",
       "74    74     NaN     NaN     NaN  0.000000  1.000000  0.000000        -inf   \n",
       "9      9     NaN     NaN     NaN  1.000000  0.000000  0.000000    0.000000   \n",
       "88    88     NaN     NaN     NaN  0.000000  1.000000  0.000000        -inf   \n",
       "25    25     NaN     NaN     NaN  0.996094  0.003906  0.000000   -0.003914   \n",
       "5      5     NaN     NaN     NaN  1.000000  0.000000  0.000000    0.000000   \n",
       "48    48     NaN     NaN     NaN  1.000000  0.000000  0.000000    0.000000   \n",
       "117  117     NaN     NaN     NaN  0.000000  0.000000  1.000000        -inf   \n",
       "83    83     NaN     NaN     NaN  0.000000  0.699219  0.300781        -inf   \n",
       "105  105     NaN     NaN     NaN  0.000000  0.000000  1.000000        -inf   \n",
       "27    27     NaN     NaN     NaN  1.000000  0.000000  0.000000    0.000000   \n",
       "64    64     NaN     NaN     NaN  0.000000  1.000000  0.000000        -inf   \n",
       "\n",
       "     LogProba_1  LogProba_2  Decision  \n",
       "114        -inf    0.000000         2  \n",
       "74     0.000000        -inf         1  \n",
       "9          -inf        -inf         0  \n",
       "88     0.000000        -inf         1  \n",
       "25    -5.545177        -inf         0  \n",
       "5          -inf        -inf         0  \n",
       "48         -inf        -inf         0  \n",
       "117        -inf    0.000000         2  \n",
       "83    -0.357792   -1.201372         1  \n",
       "105        -inf    0.000000         2  \n",
       "27         -inf        -inf         0  \n",
       "64     0.000000        -inf         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_outputs = pd.DataFrame()\n",
    "X = df[metadata['features']].values\n",
    "skl_output_key = pd.DataFrame(list(range(X.shape[0])), columns=['idx']);\n",
    "\n",
    "skl_output_score = pd.DataFrame(columns=['Score_0', 'Score_1', 'Score_2']);\n",
    "skl_output_proba = pd.DataFrame(clf.predict_proba(X), columns=['Proba_0', 'Proba_1', 'Proba_2'])\n",
    "skl_output_log_proba = pd.DataFrame(clf.predict_log_proba(X), columns=['LogProba_0', 'LogProba_1', 'LogProba_2'])\n",
    "skl_output_decision = pd.DataFrame(clf.predict(X), columns=['Decision'])\n",
    "skl_output = pd.concat([skl_output_key, skl_output_score, skl_output_proba, skl_output_log_proba, skl_output_decision] , axis=1)\n",
    "skl_output.sample(12, random_state=1960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cpp_skl_join = skl_output.join(cpp_output , how='left', on='idx', lsuffix='_skl', rsuffix='_cpp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx_skl</th>\n",
       "      <th>Score_0_skl</th>\n",
       "      <th>Score_1_skl</th>\n",
       "      <th>Score_2_skl</th>\n",
       "      <th>Proba_0_skl</th>\n",
       "      <th>Proba_1_skl</th>\n",
       "      <th>Proba_2_skl</th>\n",
       "      <th>LogProba_0_skl</th>\n",
       "      <th>LogProba_1_skl</th>\n",
       "      <th>LogProba_2_skl</th>\n",
       "      <th>...</th>\n",
       "      <th>Score_1_cpp</th>\n",
       "      <th>Score_2_cpp</th>\n",
       "      <th>Proba_0_cpp</th>\n",
       "      <th>Proba_1_cpp</th>\n",
       "      <th>Proba_2_cpp</th>\n",
       "      <th>LogProba_0_cpp</th>\n",
       "      <th>LogProba_1_cpp</th>\n",
       "      <th>LogProba_2_cpp</th>\n",
       "      <th>Decision_cpp</th>\n",
       "      <th>DecisionProba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003914</td>\n",
       "      <td>-5.545177</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003914</td>\n",
       "      <td>-5.545177</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699219</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-0.357792</td>\n",
       "      <td>-1.201372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.697266</td>\n",
       "      <td>0.302734</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-0.360589</td>\n",
       "      <td>-1.194900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.697266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.236191</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx_skl Score_0_skl Score_1_skl Score_2_skl  Proba_0_skl  Proba_1_skl  \\\n",
       "114      114         NaN         NaN         NaN     0.000000     0.000000   \n",
       "74        74         NaN         NaN         NaN     0.000000     1.000000   \n",
       "9          9         NaN         NaN         NaN     1.000000     0.000000   \n",
       "88        88         NaN         NaN         NaN     0.000000     1.000000   \n",
       "25        25         NaN         NaN         NaN     0.996094     0.003906   \n",
       "5          5         NaN         NaN         NaN     1.000000     0.000000   \n",
       "48        48         NaN         NaN         NaN     1.000000     0.000000   \n",
       "117      117         NaN         NaN         NaN     0.000000     0.000000   \n",
       "83        83         NaN         NaN         NaN     0.000000     0.699219   \n",
       "105      105         NaN         NaN         NaN     0.000000     0.000000   \n",
       "27        27         NaN         NaN         NaN     1.000000     0.000000   \n",
       "64        64         NaN         NaN         NaN     0.000000     1.000000   \n",
       "\n",
       "     Proba_2_skl  LogProba_0_skl  LogProba_1_skl  LogProba_2_skl  ...  \\\n",
       "114     1.000000            -inf            -inf        0.000000  ...   \n",
       "74      0.000000            -inf        0.000000            -inf  ...   \n",
       "9       0.000000        0.000000            -inf            -inf  ...   \n",
       "88      0.000000            -inf        0.000000            -inf  ...   \n",
       "25      0.000000       -0.003914       -5.545177            -inf  ...   \n",
       "5       0.000000        0.000000            -inf            -inf  ...   \n",
       "48      0.000000        0.000000            -inf            -inf  ...   \n",
       "117     1.000000            -inf            -inf        0.000000  ...   \n",
       "83      0.300781            -inf       -0.357792       -1.201372  ...   \n",
       "105     1.000000            -inf            -inf        0.000000  ...   \n",
       "27      0.000000        0.000000            -inf            -inf  ...   \n",
       "64      0.000000            -inf        0.000000            -inf  ...   \n",
       "\n",
       "     Score_1_cpp  Score_2_cpp  Proba_0_cpp  Proba_1_cpp  Proba_2_cpp  \\\n",
       "114          NaN          NaN     0.000000     0.000000     1.000000   \n",
       "74           NaN          NaN     0.000000     1.000000     0.000000   \n",
       "9            NaN          NaN     1.000000     0.000000     0.000000   \n",
       "88           NaN          NaN     0.000000     1.000000     0.000000   \n",
       "25           NaN          NaN     0.996094     0.003906     0.000000   \n",
       "5            NaN          NaN     1.000000     0.000000     0.000000   \n",
       "48           NaN          NaN     1.000000     0.000000     0.000000   \n",
       "117          NaN          NaN     0.000000     0.000000     1.000000   \n",
       "83           NaN          NaN     0.000000     0.697266     0.302734   \n",
       "105          NaN          NaN     0.000000     0.000000     1.000000   \n",
       "27           NaN          NaN     1.000000     0.000000     0.000000   \n",
       "64           NaN          NaN     0.000000     1.000000     0.000000   \n",
       "\n",
       "     LogProba_0_cpp  LogProba_1_cpp  LogProba_2_cpp  Decision_cpp  \\\n",
       "114      -32.236191      -32.236191        0.000000             2   \n",
       "74       -32.236191        0.000000      -32.236191             1   \n",
       "9          0.000000      -32.236191      -32.236191             0   \n",
       "88       -32.236191        0.000000      -32.236191             1   \n",
       "25        -0.003914       -5.545177      -32.236191             0   \n",
       "5          0.000000      -32.236191      -32.236191             0   \n",
       "48         0.000000      -32.236191      -32.236191             0   \n",
       "117      -32.236191      -32.236191        0.000000             2   \n",
       "83       -32.236191       -0.360589       -1.194900             1   \n",
       "105      -32.236191      -32.236191        0.000000             2   \n",
       "27         0.000000      -32.236191      -32.236191             0   \n",
       "64       -32.236191        0.000000      -32.236191             1   \n",
       "\n",
       "     DecisionProba  \n",
       "114       1.000000  \n",
       "74        1.000000  \n",
       "9         1.000000  \n",
       "88        1.000000  \n",
       "25        0.996094  \n",
       "5         1.000000  \n",
       "48        1.000000  \n",
       "117       1.000000  \n",
       "83        0.697266  \n",
       "105       1.000000  \n",
       "27        1.000000  \n",
       "64        1.000000  \n",
       "\n",
       "[12 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_skl_join.sample(12, random_state=1960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx_skl</th>\n",
       "      <th>Score_0_skl</th>\n",
       "      <th>Score_1_skl</th>\n",
       "      <th>Score_2_skl</th>\n",
       "      <th>Proba_0_skl</th>\n",
       "      <th>Proba_1_skl</th>\n",
       "      <th>Proba_2_skl</th>\n",
       "      <th>LogProba_0_skl</th>\n",
       "      <th>LogProba_1_skl</th>\n",
       "      <th>LogProba_2_skl</th>\n",
       "      <th>...</th>\n",
       "      <th>Score_1_cpp</th>\n",
       "      <th>Score_2_cpp</th>\n",
       "      <th>Proba_0_cpp</th>\n",
       "      <th>Proba_1_cpp</th>\n",
       "      <th>Proba_2_cpp</th>\n",
       "      <th>LogProba_0_cpp</th>\n",
       "      <th>LogProba_1_cpp</th>\n",
       "      <th>LogProba_2_cpp</th>\n",
       "      <th>Decision_cpp</th>\n",
       "      <th>DecisionProba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [idx_skl, Score_0_skl, Score_1_skl, Score_2_skl, Proba_0_skl, Proba_1_skl, Proba_2_skl, LogProba_0_skl, LogProba_1_skl, LogProba_2_skl, Decision_skl, idx_cpp, Score_0_cpp, Score_1_cpp, Score_2_cpp, Proba_0_cpp, Proba_1_cpp, Proba_2_cpp, LogProba_0_cpp, LogProba_1_cpp, LogProba_2_cpp, Decision_cpp, DecisionProba]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = (cpp_skl_join.Decision_cpp != cpp_skl_join.Decision_skl)\n",
    "cpp_skl_join[condition]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
